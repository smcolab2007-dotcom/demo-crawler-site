# demo-crawler-site
A simple educational demo showing how to build and test a basic web page and an ethical web crawler. Designed for teaching and learning purposes. Follow ethical practices: crawl only allowed sites, respect robots.txt, and never collect or share private data.


*** Instructions to students:
## âš–ï¸ Safety & Ethical Notes

This project is **for learning only**.

1. âœ… Crawl only your own test site or sites that **explicitly allow** crawling.  
2. ğŸš« Never collect, store, or share private or personal data.  
3. ğŸ”’ Do **not** bypass authentication or access restricted content.  
4. ğŸ¤– Always follow `robots.txt` rules and **respect website permissions**.  

---

## ğŸ§­ How to Use

1. Open the repository in GitHub Pages (enable it under **Settings â†’ Pages**).  
2. Run `polite_crawler.py` in Google Colab or your local Python environment.  
3. Observe how the crawler politely checks `robots.txt` and avoids restricted pages.

---

## ğŸ“˜ License

This demo is released for **educational use only** â€” not for production or commercial crawling.
