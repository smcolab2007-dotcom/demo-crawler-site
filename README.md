# demo-crawler-site
A simple educational demo showing how to build and test a basic web page and an ethical web crawler. Designed for teaching and learning purposes. Follow ethical practices: crawl only allowed sites, respect robots.txt, and never collect or share private data.


*** Instructions to students:
## ⚖️ Safety & Ethical Notes

This project is **for learning only**.

1. ✅ Crawl only your own test site or sites that **explicitly allow** crawling.  
2. 🚫 Never collect, store, or share private or personal data.  
3. 🔒 Do **not** bypass authentication or access restricted content.  
4. 🤖 Always follow `robots.txt` rules and **respect website permissions**.  

---

## 🧭 How to Use

1. Open the repository in GitHub Pages (enable it under **Settings → Pages**).  
2. Run `polite_crawler.py` in Google Colab or your local Python environment.  
3. Observe how the crawler politely checks `robots.txt` and avoids restricted pages.

---

## 📘 License

This demo is released for **educational use only** — not for production or commercial crawling.
